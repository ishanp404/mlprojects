{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "19PCWzucIWb6ZvPghpEaFkQnfdwpBphcJ",
      "authorship_tag": "ABX9TyNEnw741ISfIYpZsC6u+Ulz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishanp404/mlprojects/blob/main/Road_Sign_Detection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1RlPgK1PwQWT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "import cv2\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "from keras.layers import Dropout, Conv2D, MaxPool2D, Dense, Activation, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(image_path, target_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "P2JDxo-m9iRw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = '/content/drive/MyDrive/Road Sign/images'\n",
        "annotation_directory = '/content/drive/MyDrive/Road Sign/annotations'\n",
        "\n",
        "image_files = [f for f in os.listdir(image_directory) if f.endswith('.png')]"
      ],
      "metadata": {
        "id": "syWlNqtT-9zd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_annotation_pairs = []\n",
        "for image_filename in image_files:\n",
        "    image_path = os.path.join(image_directory, image_filename)\n",
        "    annotation_path = os.path.join(annotation_directory, image_filename.replace('.png', '.xml'))\n",
        "\n",
        "    if os.path.exists(annotation_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "        annotations = []\n",
        "        for object_elem in root.findall('object'):\n",
        "            obj_info = {\n",
        "                'class': object_elem.find('name').text,\n",
        "                'xmin': int(object_elem.find('bndbox/xmin').text),\n",
        "                'ymin': int(object_elem.find('bndbox/ymin').text),\n",
        "                'xmax': int(object_elem.find('bndbox/xmax').text),\n",
        "                'ymax': int(object_elem.find('bndbox/ymax').text),\n",
        "            }\n",
        "            annotations.append(obj_info)\n",
        "\n",
        "        image_annotation_pairs.append({'image': image, 'annotations': annotations})"
      ],
      "metadata": {
        "id": "HqJ9de_Q8bC5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = {\n",
        "    'trafficlight': 0,\n",
        "    'stop': 1,\n",
        "    'speedlimit': 2,\n",
        "    'crosswalk': 3\n",
        "}\n",
        "\n",
        "for data_point in image_annotation_pairs:\n",
        "    annotations = data_point['annotations']\n",
        "    for annotation in annotations:\n",
        "        class_name = annotation['class']\n",
        "        if class_name in class_mapping:\n",
        "            annotation['class'] = class_mapping[class_name]\n",
        "        else:\n",
        "            annotation['class'] = -1\n",
        "    annotations = data_point['annotations']\n",
        "    class_labels = [annotation['class'] for annotation in annotations]\n",
        "    data_point['annotations'] = class_labels[0]"
      ],
      "metadata": {
        "id": "bXckmlOm7-ZK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(image_annotation_pairs)\n",
        "\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(image_annotation_pairs) * split_ratio)\n",
        "\n",
        "training_data = image_annotation_pairs[:split_index]\n",
        "testing_data = image_annotation_pairs[split_index:]"
      ],
      "metadata": {
        "id": "Z3AsqUUw-Pli"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = [data_point['image'] for data_point in training_data]\n",
        "y_train = [data_point['annotations'] for data_point in training_data]\n",
        "\n",
        "x_test = [data_point['image'] for data_point in testing_data]\n",
        "y_test = [data_point['annotations'] for data_point in testing_data]\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train, dtype=np.int64)\n",
        "y_test = np.array(y_test, dtype=np.int64)\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "LRL-5zjk6xTv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eBk9x7micCGA",
        "outputId": "22ee84b4-27e4-4720-cac7-20b42e5b5f1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(701, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GBcHRZv7cD4o",
        "outputId": "e6becdb1-feca-4ed9-ac36-e207b27d86b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_URL = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'"
      ],
      "metadata": {
        "id": "p2KWfivWmiBj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (None, 224, 224, 3)"
      ],
      "metadata": {
        "id": "gQkkUdLmoPpX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Dense, Activation, Dropout, Flatten\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "model = Sequential([\n",
        "    hub.KerasLayer(MODEL_URL)\n",
        "])\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"sparse_categorical_accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "S3_Wxxk1F7zd"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy'], metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8FQ2ybknTZxC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=INPUT_SHAPE)"
      ],
      "metadata": {
        "id": "ANfOl61ZqYtz"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmipU_9Ym_Kx",
        "outputId": "f6d6828e-8d42-4152-e6cf-142cde354d34"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_17 (KerasLayer  (None, 1001)              5432713   \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 1001)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               128256    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 516       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5561485 (21.22 MB)\n",
            "Trainable params: 128772 (503.02 KB)\n",
            "Non-trainable params: 5432713 (20.72 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "ec = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "metadata": {
        "id": "lHTjC4cAHE6g"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=30, callbacks=[ec])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIyhU74PIyPO",
        "outputId": "83178299-e104-4eba-8862-515f3503a236"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 8s 130ms/step - loss: 1.1451 - accuracy: 0.7247 - val_loss: 0.4325 - val_accuracy: 0.8523\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.3747 - accuracy: 0.8887 - val_loss: 0.3785 - val_accuracy: 0.8580\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.3066 - accuracy: 0.9001 - val_loss: 0.3450 - val_accuracy: 0.8807\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.2125 - accuracy: 0.9330 - val_loss: 0.3230 - val_accuracy: 0.8920\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.1731 - accuracy: 0.9458 - val_loss: 0.3280 - val_accuracy: 0.8807\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.1450 - accuracy: 0.9586 - val_loss: 0.3694 - val_accuracy: 0.8864\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.1379 - accuracy: 0.9501 - val_loss: 0.3792 - val_accuracy: 0.8920\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.1137 - accuracy: 0.9601 - val_loss: 0.3694 - val_accuracy: 0.8977\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 0.0906 - accuracy: 0.9686 - val_loss: 0.3706 - val_accuracy: 0.8864\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 0.1153 - accuracy: 0.9558 - val_loss: 0.3755 - val_accuracy: 0.8864\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.0851 - accuracy: 0.9743 - val_loss: 0.3754 - val_accuracy: 0.8977\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.0589 - accuracy: 0.9872 - val_loss: 0.4228 - val_accuracy: 0.9034\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 0.3879 - val_accuracy: 0.9034\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.4398 - val_accuracy: 0.8864\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.0604 - accuracy: 0.9872 - val_loss: 0.4526 - val_accuracy: 0.8920\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 1s 69ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.4405 - val_accuracy: 0.8920\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.4479 - val_accuracy: 0.8864\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 0.0395 - accuracy: 0.9900 - val_loss: 0.4702 - val_accuracy: 0.8864\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 0.0403 - accuracy: 0.9914 - val_loss: 0.4684 - val_accuracy: 0.8977\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.0371 - accuracy: 0.9843 - val_loss: 0.4918 - val_accuracy: 0.8750\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 0.5073 - val_accuracy: 0.8864\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 0.0294 - accuracy: 0.9943 - val_loss: 0.5340 - val_accuracy: 0.8864\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.0387 - accuracy: 0.9815 - val_loss: 0.4935 - val_accuracy: 0.8920\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.4887 - val_accuracy: 0.8920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2d4965fdf0>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReyC3qecJZJV",
        "outputId": "02fda481-5d89-4f29-a467-c331f832e749"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 47ms/step - loss: 0.4887 - accuracy: 0.8920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4886554777622223, 0.8920454382896423]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cM45vK_IB0er"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}